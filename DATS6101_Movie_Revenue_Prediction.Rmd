---
title: "Predictive Model for Movie Revenue Estimation and Decision Support"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  #pdf_document:
    #toc: yes
    #toc_depth: '3'
---

```{r}
knitr::opts_chunk$set(echo = TRUE)
```

Detailed Problem Statement:
The movie industry is a dynamic and complex environment where various factors influence a movie's success, particularly its revenue. This project focuses on developing a robust "Predictive Model for Movie Revenue Estimation and Decision Support." In an era of high uncertainty and financial risk in the film production business, understanding the determinants of movie revenue is paramount for informed decision-making, investment strategies, and marketing planning.

Movies are a unique combination of artistic expression and commercial ventures. To that end, this research investigates a multitude of features that contribute to the financial performance of a movie. These include aspects like genres, original languages, overview, popularity, production companies, release date, budget, runtime, status, tagline, vote average, vote count, credits, keywords, poster path, backdrop path, and recommendations. Each of these factors is scrutinized meticulously to unravel their individual and collective influence on movie revenue.

By conducting a comprehensive analysis of these features, this research aims to build a regression model (Linear, Decision Tree, Support Vector Machine) based on valuable insights through identifying patterns, relationships, and correlations. The findings of this study are expected to have substantial implications for movie production companies, investors, and stakeholders. They can leverage the predictive model developed in this project to make informed decisions regarding their movie investments, marketing strategies, and financial planning, ultimately contributing to the success and profitability of their ventures in the film industry.

**Importing the Movies Data**

```{r}
movies = read.csv("C:\\Anand\\Projects_GWU\\DATS6101-P2-Movie-Revenue-Prediction\\movies.csv\\Movie_data.csv")
#head(movies)
summary(movies)
movie = movies # Creating a copy of data frame
```

**Removing Unwanted Columns**

```{r}
library(dplyr)
remove_col <- c(1,5,7,13,16,17,18,19,20)
movie <- movie[, -remove_col]
head(movie)
```

**Summary of the data**

```{r}
new_column_names <- c("Title", "Genre", "Language", "Popularity", "Release_Date","Budget","Revenue","Runtime","Status","Avg_Vote","Vote_Count","Trailer_Views","Trailer_Likes")
colnames(movie) <- new_column_names
summary(movie)
```

Inferences:
1. Budget of Movies are having value 0, which is not possible (Remove rows with budget 0)
2. Revenue has negative values which is again not possible (Remove rows with revenue 0 or negative)
3. Runtime of Movies are having value 0, which is not possible (Remove rows with runtime 0)
4. Check for outliers and influential points in all the columns.

**Checking for missing values in the data**

```{r}
library(ggplot2)

# Calculate the percentage of missing values in each column
column_na_percentages <- colSums(is.na(movie)) / nrow(movie) * 100

# Set a smaller font size
smaller_font_size <- 0.8

# Create a bar plot for the percentage of missing values in each column
barplot(column_na_percentages, main = "Percentage of Missing Values in Each Column",
        xlab = "Columns", ylab = "Percentage of Missing Values",
        col = "lightcoral", border = "black", ylim = c(0, 100),
        names.arg = names(column_na_percentages), las = 2, cex.names = smaller_font_size)

print("Rows in Dataset before dropping rows with NA Values")
print(nrow(movie))

movie <- movie[complete.cases(movie), ]

print("Rows in Dataset After dropping rows with NA Values")
print(nrow(movie))
```

Removed rows with NA Values

***Data Cleaning***

```{r}
print("Rows in Dataset before cleaning")
print(nrow(movie))

# 1. Remove rows with Budget less than or equal to 0
movie <- movie[movie$Budget > 0, ]

# 2. Remove rows with Revenue less than or equal to 0
movie <- movie[movie$Revenue > 0, ]

# 3. Remove rows with Runtime less than or equal to 0
movie <- movie[movie$Runtime > 0, ]

print("Rows in Dataset After cleaning")
print(nrow(movie))
```

```{r}
selected_columns <- c("Popularity", "Budget", "Revenue", "Runtime", "Avg_Vote", "Vote_Count", "Trailer_Views","Trailer_Likes")

box_plots_list <- list()

# Create box plots for each selected column
for (col in selected_columns) {
  box_plot <- ggplot(movie, aes(y = get(col))) +
    geom_boxplot(fill = "lightblue", color = "black", alpha = 0.7) +
    labs(title = paste("Box Plot for", col), y = col) +
    theme_minimal() +
    theme(plot.title = element_text(size = 15)) +
    theme(axis.title = element_text(size = 12)) +
    theme(axis.text = element_text(size = 10))
  
  box_plots_list[[col]] <- box_plot
}

for (col in selected_columns) {
  print(box_plots_list[[col]])
}
```
**Data Visulisation**
[Scatter Plots, Correlation Heatmap etc]
```{r}
# Scatterplots
# Define the predictors and response variable
predictors <- c("Trailer_Likes", "Trailer_Views", "Vote_Count", "Budget", "Runtime", "Avg_Vote")

scatter_plots <- lapply(predictors, function(var) {
  ggplot(movie, aes(x = get(var), y = movie$Revenue)) +
    geom_point() +
    labs(title = paste("Scatter plot of", var, "vs. Revenue"))
})

# Display scatter plots
scatter_plots

```


**Stepwise Forward Feature Selection**
```{r}
library(MASS)

# Define your initial model
initial_model <- lm(Revenue ~ 1, data = movie)  # Simple model with intercept only

# Perform stepwise forward selection
final_model <- stepAIC(initial_model, direction = "forward", scope = list(lower = ~1, upper = ~Popularity + Budget + Runtime + Avg_Vote + Vote_Count + Trailer_Views + Trailer_Likes), data = movie)

# Display the final model summary
summary(final_model)

```

The features given in the final model using forward feature selection are Trailer_Likes, Trailer_Views, Vote_Count, Budget, Runtime ,Avg_Vote , popularity but we can see that the intercept is not significant hence we will build the model again with different combinations of features.

```{r}
lm_model_usingFFS <- lm(Revenue ~ Trailer_Views+Trailer_Likes+Vote_Count+Budget+Popularity, data = movie)

# Summarize the model
summary(lm_model_usingFFS)
```
```{r}
library(car)
influencePlot(lm_model_usingFFS)
```
Row 1,96,443,15996 have influence on our overall model.

```{r}
# Remove specified rows
rows_to_remove <- c(15996, 443, 96, 64, 1)
movie <- movie[-rows_to_remove, ]
```

```{r}
lm_model <- lm(Revenue ~ Trailer_Views+Trailer_Likes+Vote_Count+Budget, data = movie)

# Summarize the model
summary(lm_model)

influencePlot(lm_model)
```
In the above model we can see that all the input features are significant and we have a good Multiple R-Squared value. 
The p-value for the model is also significant indicating the model is a significant model.
The Residual Std Error is around 5.4 Million which seems a little high as we cannot exactly predict the Revenue of a Movie as it depends on various other factors.

Coefficients:

Intercept (1.156e+06): The estimated intercept of the linear regression equation when all predictor variables are zero.
Trailer_Views (3.803e-01): The estimated change in the response variable (Revenue) for a one-unit increase in "Trailer_Views" while holding other predictors constant.
Trailer_Likes (2.420e+00): Similar to "Trailer_Views," this represents the estimated change in Revenue for a one-unit increase in "Trailer_Likes."
Vote_Count (5.320e+02): Represents the estimated change in Revenue for a one-unit increase in "Vote_Count."
Budget (7.071e-03): Represents the estimated change in Revenue for a one-unit increase in "Budget."
Significance Codes:

Multiple R-squared: The proportion of the variance in the dependent variable (Revenue) that is predictable from the independent variables (Trailer_Views, Trailer_Likes, Vote_Count, Budget). In your case, it's 90.06%.

Adjusted R-squared: Similar to R-squared but adjusted for the number of predictors.

F-statistic: Tests the overall significance of the model. In your case, it's 2.415e+04 with a very low p-value, suggesting the model is significant.

The Residual Standard Error has also reduced after removal of influential points.
```{r}
library(car)
# Check of Mullticollinearity
# Calculate VIF for the linear regression model
vif_values <- vif(lm_model)

# Print the VIF values
print(vif_values)
```
All values are below 10 indicating "No" Multicollinearity between features.

```{r}
# Check for Linear Relationship with the output variable
avPlots(lm_model)
```
All features in our model seem to have linear relationship with the output variable.

```{r}
# Check for Normality of errors, Equal Variances of residuals and Independence of errors.
plot(lm_model)
```


```{r}
library(caTools)

# Set a random seed for reproducibility
set.seed(123)

# Split the data into training (80%) and testing (20%) sets
split <- sample.split(movie$Revenue, SplitRatio = 0.8)
train_data <- subset(movie, split == TRUE)
test_data <- subset(movie, split == FALSE)

# Fit linear regression model on the training data
lm_model <- lm(Revenue ~ Trailer_Views + Trailer_Likes + Vote_Count + Budget, data = train_data)

# Make predictions on the training data
train_predictions <- predict(lm_model, newdata = train_data)

# Make predictions on the test data
test_predictions <- predict(lm_model, newdata = test_data)

# Calculate Root Mean Squared Error (RMSE) for test set
test_rmse <- sqrt(mean((test_data$Revenue - test_predictions)^2))
cat("Train Root Mean Squared Error (RMSE):", test_rmse, "\n")

# Calculate Root Mean Squared Error (RMSE) for training set
train_rmse <- sqrt(mean((train_data$Revenue - train_predictions)^2))
cat("Test Root Mean Squared Error (RMSE):", train_rmse, "\n")

```


```{r}
mean_revenue <- mean(movie$Revenue, na.rm = TRUE)
median_revenue <- median(movie$Revenue, na.rm = TRUE)
quantiles_revenue <- quantile(movie$Revenue, c(0.25, 0.5, 0.75), na.rm = TRUE)

# Print the results
cat("Mean Revenue:", mean_revenue, "\n")
```

```{r linear regression evaluation}
# Fit the model on the training data
#lm_train <- lm(paste(response, "~", paste(predictors, collapse = " + ")), data = train_data)
lm_model <- lm(Revenue ~ Trailer_Views + Trailer_Likes + Vote_Count + Budget, data = train_data)
summary(lm_model)
# Fit the model on the testing data
#lm_test <- lm(paste(response, "~", paste(predictors, collapse = " + ")), data = test_data)
#summary(lm_test)
lm_train_predictions <- predict(lm_model, newdata = train_data)
lm_test_predictions <- predict(lm_model, newdata = test_data)
library(Metrics)
lm_train_rmse <- rmse(train_data$Revenue, lm_train_predictions)
lm_test_rmse <- rmse(test_data$Revenue, lm_test_predictions)
cat("Linear Regression Train Data RMSE:", lm_train_rmse, "\n")
cat("Linear Regression Test Data RMSE:", lm_test_rmse, "\n")
```

```{r ridge and lasso regression models}
# Ridge Regression
library(glmnet)
predictors <- c("Trailer_Likes", "Trailer_Views", "Vote_Count", "Budget")
ridge_model <- glmnet(as.matrix(train_data[predictors]), train_data$Revenue, alpha=0, lambda=1)

# Lasso Regression
lasso_model <- glmnet(as.matrix(train_data[predictors]), train_data$Revenue, alpha=1, lambda=1)

# Predictions
ridge_train_predictions <- predict(ridge_model, newx = as.matrix(train_data[predictors]))
lasso_train_predictions <- predict(lasso_model, newx = as.matrix(train_data[predictors]))
ridge_test_predictions <- predict(ridge_model, newx = as.matrix(test_data[predictors]))
lasso_test_predictions <- predict(lasso_model, newx = as.matrix(test_data[predictors]))

# Root Mean Squared Error
library(Metrics)
ridge_train_rmse <- rmse(train_data$Revenue, ridge_train_predictions)
ridge_test_rmse <- rmse(test_data$Revenue, ridge_test_predictions)
lasso_train_rmse <- rmse(train_data$Revenue, lasso_train_predictions)
lasso_test_rmse <- rmse(test_data$Revenue, lasso_test_predictions)

# Print the results
cat("Linear Regression Train Data RMSE:", lm_train_rmse, "\n")
cat("Linear Regression Test Data RMSE:", lm_test_rmse, "\n")
cat("Ridge Regression Train RMSE:", ridge_train_rmse, "\n")
cat("Ridge Regression Test RMSE:", ridge_test_rmse, "\n")
cat("Lasso Regression Train RMSE:", lasso_train_rmse, "\n")
cat("Lasso Regression Test RMSE:", lasso_test_rmse, "\n")
```

```{r ridge and lasso regression tuning}
library(glmnet)
set.seed(42)

# Prepare data
X <- as.matrix(train_data[predictors])
y <- as.matrix(train_data$Revenue)

# Create an lambda range
lambdas <- 10^seq(10, -1, length = 1000)

# Find the best lambda using cross validation
ridge_cv_model <- cv.glmnet(X, y, alpha = 0, lambda = lambdas)
lasso_cv_model <- cv.glmnet(X, y, alpha = 1, lambda = lambdas)

# Get the best lambda value
best_lambda_ridge <- ridge_cv_model$lambda.min
best_lambda_lasso <- lasso_cv_model$lambda.min

# Print the best lambda value
cat("Best lambda value for Ridge Regression: ", best_lambda_ridge, "\n")
cat("Best lambda value for Lasso Regression: ", best_lambda_lasso, "\n")

ridge_coef <- predict(ridge_model, type = "coefficients", s = best_lambda_ridge)
lasso_coef <- predict(lasso_model, type = "coefficients", s = best_lambda_lasso)
#cat("Ridge Regression Coefs: ", ridge_coef, "\n")
#cat("Lasso Regression Coefs: ", lasso_coef, "\n")
ridge_coef
lasso_coef

# Predictions
ridgetuned_train_predictions <- predict(ridge_cv_model, s = best_lambda_ridge, newx = as.matrix(train_data[predictors]))
ridgetuned_test_predictions <- predict(ridge_cv_model, s = best_lambda_ridge, newx = as.matrix(test_data[predictors]))
lassotuned_train_predictions <- predict(lasso_cv_model, s = best_lambda_lasso, newx = as.matrix(train_data[predictors]))
lassotuned_test_predictions <- predict(lasso_cv_model, s = best_lambda_lasso, newx = as.matrix(test_data[predictors]))

# Root Mean Squared Error
library(Metrics)
ridgetuned_train_rmse <- rmse(train_data$Revenue, ridgetuned_train_predictions)
ridgetuned_test_rmse <- rmse(test_data$Revenue, ridgetuned_test_predictions)
lassotuned_train_rmse <- rmse(train_data$Revenue, lassotuned_train_predictions)
lassotuned_test_rmse <- rmse(test_data$Revenue, lassotuned_test_predictions)

# Print the results
cat("Linear Regression Train Data RMSE:", lm_train_rmse, "\n")
cat("Linear Regression Test Data RMSE:", lm_test_rmse, "\n")
cat("Ridge Regression Train RMSE (tuned):", ridgetuned_train_rmse, "\n")
cat("Ridge Regression Test RMSE (tuned):", ridgetuned_test_rmse, "\n")
cat("Lasso Regression Train RMSE (tuned):", lassotuned_train_rmse, "\n")
cat("Lasso Regression Test RMSE (tuned):", lassotuned_test_rmse, "\n")

plot(ridge_cv_model)
plot(lasso_cv_model)

```

```{r ridge and lasso regression tuning2}
library(glmnet)
set.seed(42)

# Create an lambda range
lambdas1 <- 10^seq(1, -1, length = 1000)
lambdas2 <- 10^seq(13, 4, length = 1000)

# Find the best lambda using cross validation
ridge_cv_model <- cv.glmnet(X, y, alpha = 0, lambda = lambdas1)
lasso_cv_model <- cv.glmnet(X, y, alpha = 1, lambda = lambdas2)

# Get the best lambda value
best_lambda_ridge <- ridge_cv_model$lambda.min
best_lambda_lasso <- lasso_cv_model$lambda.min

# Print the best lambda value
cat("Best lambda value for Ridge Regression: ", best_lambda_ridge, "\n")
cat("Best lambda value for Lasso Regression: ", best_lambda_lasso, "\n")

ridge_coef <- predict(ridge_model, type = "coefficients", s = best_lambda_ridge)
lasso_coef <- predict(lasso_model, type = "coefficients", s = best_lambda_lasso)
#cat("Ridge Regression Coefs: ", ridge_coef, "\n")
#cat("Lasso Regression Coefs: ", lasso_coef, "\n")
ridge_coef
lasso_coef

# Predictions
ridgetuned_train_predictions <- predict(ridge_cv_model, s = best_lambda_ridge, newx = as.matrix(train_data[predictors]))
ridgetuned_test_predictions <- predict(ridge_cv_model, s = best_lambda_ridge, newx = as.matrix(test_data[predictors]))
lassotuned_train_predictions <- predict(lasso_cv_model, s = best_lambda_lasso, newx = as.matrix(train_data[predictors]))
lassotuned_test_predictions <- predict(lasso_cv_model, s = best_lambda_lasso, newx = as.matrix(test_data[predictors]))

# Root Mean Squared Error
library(Metrics)
ridgetuned_train_rmse <- rmse(train_data$Revenue, ridgetuned_train_predictions)
ridgetuned_test_rmse <- rmse(test_data$Revenue, ridgetuned_test_predictions)
lassotuned_train_rmse <- rmse(train_data$Revenue, lassotuned_train_predictions)
lassotuned_test_rmse <- rmse(test_data$Revenue, lassotuned_test_predictions)

# Print the results
cat("Linear Regression Train Data RMSE:", lm_train_rmse, "\n")
cat("Linear Regression Test Data RMSE:", lm_test_rmse, "\n")
cat("Ridge Regression Train RMSE (tuned):", ridgetuned_train_rmse, "\n")
cat("Ridge Regression Test RMSE (tuned):", ridgetuned_test_rmse, "\n")
cat("Lasso Regression Train RMSE (tuned):", lassotuned_train_rmse, "\n")
cat("Lasso Regression Test RMSE (tuned):", lassotuned_test_rmse, "\n")

plot(ridge_cv_model)
plot(lasso_cv_model)
```
